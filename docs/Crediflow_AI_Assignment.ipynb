{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Core system dependencies\n",
        "!apt-get update && apt-get install -y \\\n",
        "    poppler-utils \\\n",
        "    tesseract-ocr\n",
        "\n",
        "# Required Python packages\n",
        "!pip install \\\n",
        "    pytesseract \\\n",
        "    pdf2image \\\n",
        "    PyPDF2 \\\n",
        "    pandas \\\n",
        "    openai \\\n",
        "    striprtf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atxJsOh4cwx7",
        "outputId": "a0e36757-4c27-40cd-e463-06a5c06f1193"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [1 InRelease 3,632 B/3\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to r2u.stat\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                                                    \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,317 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,662 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,939 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,703 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,526 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,610 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,230 kB]\n",
            "Fetched 21.4 MB in 3s (8,227 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 4 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 5,002 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 5,002 kB in 2s (2,964 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: striprtf in /usr/local/lib/python3.11/dist-packages (0.0.28)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "PDF and Vocabulary Text Extractor\n",
        "--------------------------------\n",
        "Checkpoint 1: Extract and validate text from input files\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "import PyPDF2\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "import json\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TextExtractor:\n",
        "    def __init__(self, pdf_path: str, vocab_path: str):\n",
        "        \"\"\"Initialize paths and directories\"\"\"\n",
        "        self.pdf_path = Path(pdf_path)\n",
        "        self.vocab_path = Path(vocab_path)\n",
        "\n",
        "        # Set up output directory\n",
        "        self.output_dir = Path(\"extracted_data\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Output file paths\n",
        "        self.text_output = self.output_dir / \"extracted_text.txt\"\n",
        "        self.vocab_output = self.output_dir / \"processed_vocabulary.json\"\n",
        "        self.validation_log = self.output_dir / \"extraction_validation.log\"\n",
        "\n",
        "        # Initialize processing log\n",
        "        self.processing_log = []\n",
        "\n",
        "    def extract_all(self) -> Tuple[str, List[str]]:\n",
        "        \"\"\"Main extraction pipeline\"\"\"\n",
        "        try:\n",
        "            # Process PDF\n",
        "            pdf_text = self.process_pdf()\n",
        "            self._log(\"PDF processing complete\")\n",
        "\n",
        "            # Process vocabulary\n",
        "            vocabulary = self.process_vocabulary()\n",
        "            self._log(\"Vocabulary processing complete\")\n",
        "\n",
        "            # Save outputs\n",
        "            self.save_outputs(pdf_text, vocabulary)\n",
        "            self._log(\"Outputs saved\")\n",
        "\n",
        "            # Validate results\n",
        "            self.validate_extraction(pdf_text, vocabulary)\n",
        "\n",
        "            return pdf_text, vocabulary\n",
        "\n",
        "        except Exception as e:\n",
        "            self._log_error(f\"Extraction failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def process_pdf(self) -> str:\n",
        "        \"\"\"Process PDF file with readability check\"\"\"\n",
        "        try:\n",
        "            # Try direct extraction first\n",
        "            text = self._extract_pdf_text()\n",
        "\n",
        "            # Check if extracted text is readable\n",
        "            if self._is_text_readable(text):\n",
        "                self._log(\"Direct PDF extraction successful\")\n",
        "                return text\n",
        "\n",
        "            # If not readable, use OCR\n",
        "            self._log(\"Direct extraction insufficient, attempting OCR\")\n",
        "            return self._process_pdf_ocr()\n",
        "\n",
        "        except Exception as e:\n",
        "            self._log_error(f\"PDF processing failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_pdf_text(self) -> str:\n",
        "        \"\"\"Extract text directly from PDF\"\"\"\n",
        "        extracted_text = []\n",
        "\n",
        "        with open(self.pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "            for i, page in enumerate(reader.pages):\n",
        "                text = page.extract_text() or \"\"\n",
        "                if text.strip():\n",
        "                    extracted_text.append(f\"--- Page {i+1} ---\\n{text}\\n\")\n",
        "                self._log(f\"Processed page {i+1} directly\")\n",
        "\n",
        "        return \"\\n\".join(extracted_text)\n",
        "\n",
        "    def _is_text_readable(self, text: str) -> bool:\n",
        "        \"\"\"Check if extracted text is readable\"\"\"\n",
        "        if not text.strip():\n",
        "            return False\n",
        "\n",
        "        # Check for minimum content\n",
        "        words = text.split()\n",
        "        if len(words) < 100:  # Arbitrary threshold\n",
        "            return False\n",
        "\n",
        "        # Check for common financial terms\n",
        "        financial_terms = ['assets', 'liabilities', 'revenue', 'profit', 'loss']\n",
        "        found_terms = sum(1 for term in financial_terms if term.lower() in text.lower())\n",
        "\n",
        "        return found_terms >= 2\n",
        "\n",
        "    def _process_pdf_ocr(self) -> str:\n",
        "        \"\"\"Process PDF using OCR\"\"\"\n",
        "        extracted_text = []\n",
        "\n",
        "        # Convert PDF to images\n",
        "        images = convert_from_path(str(self.pdf_path))\n",
        "\n",
        "        for i, image in enumerate(images):\n",
        "            # Apply OCR with configuration\n",
        "            text = pytesseract.image_to_string(\n",
        "                image,\n",
        "                config='--psm 6 --oem 3'  # Assume uniform text block\n",
        "            )\n",
        "\n",
        "            if text.strip():\n",
        "                extracted_text.append(f\"--- Page {i+1} ---\\n{text}\\n\")\n",
        "            self._log(f\"OCR processed page {i+1}\")\n",
        "\n",
        "        return \"\\n\".join(extracted_text)\n",
        "\n",
        "    def process_vocabulary(self) -> List[str]:\n",
        "        \"\"\"Process vocabulary file\"\"\"\n",
        "        try:\n",
        "            with open(self.vocab_path, 'r') as f:\n",
        "                content = rtf_to_text(f.read())\n",
        "\n",
        "            # Clean and extract terms\n",
        "            terms = [\n",
        "                term.strip(' \",\\\\')\n",
        "                for term in content.split(',')\n",
        "                if term.strip()\n",
        "            ]\n",
        "\n",
        "            # Remove duplicates and sort\n",
        "            terms = sorted(list(set(\n",
        "                term for term in terms\n",
        "                if term and not term.startswith('{')\n",
        "            )))\n",
        "\n",
        "            self._log(f\"Processed {len(terms)} vocabulary terms\")\n",
        "            return terms\n",
        "\n",
        "        except Exception as e:\n",
        "            self._log_error(f\"Vocabulary processing failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def save_outputs(self, text: str, vocabulary: List[str]):\n",
        "        \"\"\"Save extracted data to files\"\"\"\n",
        "        # Save extracted text\n",
        "        with open(self.text_output, 'w', encoding='utf-8') as f:\n",
        "            f.write(text)\n",
        "\n",
        "        # Save vocabulary\n",
        "        with open(self.vocab_output, 'w', encoding='utf-8') as f:\n",
        "            json.dump(vocabulary, f, indent=2)\n",
        "\n",
        "        # Save processing log\n",
        "        with open(self.validation_log, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(self.processing_log))\n",
        "\n",
        "    def validate_extraction(self, text: str, vocabulary: List[str]):\n",
        "        \"\"\"Validate extracted content\"\"\"\n",
        "        validations = []\n",
        "\n",
        "        # Check text extraction\n",
        "        validations.append(f\"Text length: {len(text)} characters\")\n",
        "        validations.append(f\"Number of pages found: {text.count('--- Page')}\")\n",
        "\n",
        "        # Check vocabulary\n",
        "        validations.append(f\"Vocabulary terms: {len(vocabulary)}\")\n",
        "        validations.append(f\"Sample terms: {', '.join(vocabulary[:5])}...\")\n",
        "\n",
        "        # Add validations to log\n",
        "        for validation in validations:\n",
        "            self._log(f\"Validation: {validation}\")\n",
        "\n",
        "    def _log(self, message: str):\n",
        "        \"\"\"Log information message\"\"\"\n",
        "        self.processing_log.append(f\"INFO: {message}\")\n",
        "        logger.info(message)\n",
        "\n",
        "    def _log_error(self, message: str):\n",
        "        \"\"\"Log error message\"\"\"\n",
        "        self.processing_log.append(f\"ERROR: {message}\")\n",
        "        logger.error(message)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    try:\n",
        "        # Initialize extractor\n",
        "        extractor = TextExtractor(\n",
        "            pdf_path=\"/content/vodafone_annual_report.pdf\",\n",
        "            vocab_path=\"/content/vocabulary.rtf\"\n",
        "        )\n",
        "\n",
        "        # Process files\n",
        "        text, vocabulary = extractor.extract_all()\n",
        "\n",
        "        # Print summary\n",
        "        print(\"\\n✅ EXTRACTION COMPLETE\")\n",
        "        print(f\"\\nOutputs saved to: {extractor.output_dir}\")\n",
        "        print(f\"- Extracted text: {extractor.text_output}\")\n",
        "        print(f\"- Processed vocabulary: {extractor.vocab_output}\")\n",
        "        print(f\"- Validation log: {extractor.validation_log}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ EXTRACTION FAILED: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlng8w6M5JzF",
        "outputId": "4d371173-4fdd-45c4-f7ea-ce8c4409d918"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ EXTRACTION COMPLETE\n",
            "\n",
            "Outputs saved to: extracted_data\n",
            "- Extracted text: extracted_data/extracted_text.txt\n",
            "- Processed vocabulary: extracted_data/processed_vocabulary.json\n",
            "- Validation log: extracted_data/extraction_validation.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Financial Table Extractor\n",
        "------------------------\n",
        "Purpose: Extract financial tables from preprocessed text using GPT-4\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class FinancialTableExtractor:\n",
        "    def __init__(self, extracted_text_path: str):\n",
        "        # Initialize OpenAI client with CLY secret\n",
        "        self.client = OpenAI(api_key=userdata.get('CLY'))\n",
        "\n",
        "        # Paths\n",
        "        self.input_path = Path(extracted_text_path)\n",
        "        self.output_dir = Path(\"financial_tables\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def extract_tables(self) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Extract financial tables from text\"\"\"\n",
        "        try:\n",
        "            # Load extracted text\n",
        "            with open(self.input_path, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            # Extract tables using GPT-4\n",
        "            tables = self._extract_tables_gpt(text)\n",
        "\n",
        "            # Process and save tables\n",
        "            processed_tables = self._process_tables(tables)\n",
        "\n",
        "            # Save tables\n",
        "            self._save_tables(processed_tables)\n",
        "\n",
        "            return processed_tables\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Table extraction failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _extract_tables_gpt(self, text: str) -> Dict[str, str]:\n",
        "        \"\"\"Extract tables using GPT-4\"\"\"\n",
        "        prompt = \"\"\"\n",
        "        Extract these financial tables exactly as they appear in the text:\n",
        "        1. Balance Sheet / Statement of Financial Position\n",
        "        2. Income Statement / Profit & Loss Statement\n",
        "        3. Cash Flow Statement (if present)\n",
        "\n",
        "        Requirements:\n",
        "        - Keep ALL line items and numbers EXACTLY as shown\n",
        "        - Preserve negative values in parentheses\n",
        "        - Include all subtotals and totals\n",
        "        - Maintain hierarchy and formatting\n",
        "        - Keep original labels and capitalization\n",
        "\n",
        "        For each table:\n",
        "        - Start with the exact table name as shown in document\n",
        "        - Include all columns with exact headers\n",
        "        - Keep numerical formatting exactly as shown\n",
        "\n",
        "        Format as:\n",
        "        ### [EXACT TABLE NAME]\n",
        "        | Line Item | [Year Header 1] | [Year Header 2] |\n",
        "        |-----------|----------------|----------------|\n",
        "        | [exact item] | [exact value] | [exact value] |\n",
        "\n",
        "        Use [TABLE_BREAK] between tables.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a financial statement expert. Extract tables exactly as they appear, preserving all formatting and details.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"{prompt}\\n\\n{text}\"\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Parse response into tables\n",
        "            tables = {}\n",
        "            current_table = None\n",
        "            current_content = []\n",
        "\n",
        "            for line in response.choices[0].message.content.split('\\n'):\n",
        "                if line.startswith('### '):\n",
        "                    if current_table:\n",
        "                        tables[current_table] = '\\n'.join(current_content)\n",
        "                    current_table = line.replace('### ', '').strip()\n",
        "                    current_content = []\n",
        "                elif line.strip():\n",
        "                    current_content.append(line)\n",
        "\n",
        "            if current_table and current_content:\n",
        "                tables[current_table] = '\\n'.join(current_content)\n",
        "\n",
        "            return tables\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"GPT extraction failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _process_tables(self, tables: Dict[str, str]) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Convert extracted tables to DataFrames\"\"\"\n",
        "        processed = {}\n",
        "\n",
        "        for name, content in tables.items():\n",
        "            try:\n",
        "                # Parse table content\n",
        "                rows = [\n",
        "                    [cell.strip() for cell in row.split('|')[1:-1]]\n",
        "                    for row in content.split('\\n')\n",
        "                    if row.strip() and '|-' not in row\n",
        "                ]\n",
        "\n",
        "                if not rows:\n",
        "                    continue\n",
        "\n",
        "                # Create DataFrame preserving exact formatting\n",
        "                df = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "\n",
        "                # Clean up any extra whitespace while preserving formatting\n",
        "                df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "                processed[name] = df\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Failed to process table {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return processed\n",
        "\n",
        "    def _save_tables(self, tables: Dict[str, pd.DataFrame]):\n",
        "        \"\"\"Save tables in multiple formats\"\"\"\n",
        "        # Save as markdown\n",
        "        with open(self.output_dir / \"financial_tables.md\", 'w') as f:\n",
        "            f.write(\"# Extracted Financial Tables\\n\\n\")\n",
        "            for name, df in tables.items():\n",
        "                f.write(f\"## {name}\\n\")\n",
        "                f.write(df.to_markdown(index=False))\n",
        "                f.write(\"\\n\\n\")\n",
        "\n",
        "        # Save individual CSV files\n",
        "        for name, df in tables.items():\n",
        "            safe_name = \"\".join(c for c in name if c.isalnum() or c in (' ', '_')).strip()\n",
        "            df.to_csv(self.output_dir / f\"{safe_name}.csv\", index=False)\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        extractor = FinancialTableExtractor(\n",
        "            extracted_text_path=\"extracted_data/extracted_text.txt\"\n",
        "        )\n",
        "\n",
        "        # Extract tables\n",
        "        tables = extractor.extract_tables()\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n✅ TABLE EXTRACTION COMPLETE\")\n",
        "        print(\"\\nExtracted Tables:\")\n",
        "        for name, df in tables.items():\n",
        "            print(f\"\\n## {name}\")\n",
        "            print(df.to_markdown(index=False))\n",
        "\n",
        "        print(f\"\\nTables saved to: {extractor.output_dir}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ EXTRACTION FAILED: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7KOIdtRfUPJ",
        "outputId": "9261942e-7461-4d94-9d7e-6b8be458cbd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ TABLE EXTRACTION COMPLETE\n",
            "\n",
            "Extracted Tables:\n",
            "\n",
            "## INCOME STATEMENT\n",
            "| Line Item                                   | 2020      | 2019      |\n",
            "|:--------------------------------------------|:----------|:----------|\n",
            "| Revenue                                     | 5,657.6   | 5,512.9   |\n",
            "| Cost of sales                               | (4,045.5) | (4,222.2) |\n",
            "| Gross profit                                | 1,612.1   | 1,290.7   |\n",
            "| Selling and distribution costs              | (578.1)   | (637.8)   |\n",
            "| Administrative expenses                     | (1,284.2) | (1,255.0) |\n",
            "| Net credit losses on financial assets       | (101.3)   | (74.7)    |\n",
            "| Operating loss                              | (351.5)   | (676.8)   |\n",
            "| Net finance expense                         | (23.5)    | (2.7)     |\n",
            "| Loss on ordinary activities before taxation | (375.0)   | (679.5)   |\n",
            "| Income tax on ordinary activities           | 148.8     | 92.3      |\n",
            "| Loss for the financial year                 | (226.2)   | (587.2)   |\n",
            "|                                             |           |           |\n",
            "\n",
            "## STATEMENT OF FINANCIAL POSITION\n",
            "| Line Item                                               | 2020      | 2019      |\n",
            "|:--------------------------------------------------------|:----------|:----------|\n",
            "| Non-current assets                                      |           |           |\n",
            "| Intangible assets                                       | 2,368.4   | 2,794.1   |\n",
            "| Property, plant and equipment                           | 3,965.3   | 3,040.7   |\n",
            "| Investments                                             | 25.1      | 25.1      |\n",
            "| Deferred tax asset                                      | 1,124.2   | 1,014.3   |\n",
            "| Post-employment benefits - asset                        | 489.2     | 81.4      |\n",
            "| TOTAL NON-CURRENT ASSETS                                | 7,972.2   | 6,955.6   |\n",
            "| Current assets                                          |           |           |\n",
            "| Inventories                                             | 116.4     | 160.9     |\n",
            "| Trade and other receivables                             | 3,582.2   | 3,400.8   |\n",
            "| Cash and cash equivalents                               | 243       | 32.5      |\n",
            "| TOTAL CURRENT ASSETS                                    | 3,722.9   | 3,594.2   |\n",
            "| Creditors: amounts falling due within one year          | (4,605.2) | (4,215.1) |\n",
            "| NET CURRENT LIABILITIES                                 | (882.3)   | (620.9)   |\n",
            "| TOTAL ASSETS LESS CURRENT LIABILITIES                   | 7,089.9   | 6,334.7   |\n",
            "| Creditors: amounts falling due after more than one year | (743.3)   | (21.6)    |\n",
            "| Provisions for liabilities                              | (217.1)   | (286.0)   |\n",
            "| Post-employment benefits - liability                    | (19.2)    | (178.7)   |\n",
            "| NET ASSETS                                              | 6,110.3   | 5,848.4   |\n",
            "| EQUITY                                                  |           |           |\n",
            "| Called up share capital                                 | -         | -         |\n",
            "| Share premium account                                   | 9,168.2   | 9,168.2   |\n",
            "| Retained earnings                                       | (3,057.9) | (3,319.8) |\n",
            "| TOTAL SHAREHOLDERS’ FUNDS                               | 6,110.3   | 5,848.4   |\n",
            "|                                                         |           |           |\n",
            "\n",
            "## STATEMENT OF COMPREHENSIVE INCOME\n",
            "| Line Item                                                                 | 2020    | 2019    |\n",
            "|:--------------------------------------------------------------------------|:--------|:--------|\n",
            "| Loss for the financial year                                               | (226.2) | (587.2) |\n",
            "| Other comprehensive income/(expense):                                     |         |         |\n",
            "| Items that will not be reclassified to profit or loss                     |         |         |\n",
            "| Actuarial gains/(losses) in the value of defined benefit retirement plans | 569.7   | (31.7)  |\n",
            "| Cash flow hedging reserve                                                 | 6.7     | (0.1)   |\n",
            "| Tax attributable to actuarial gains/(losses)                              | (106.5) | 5.2     |\n",
            "| Other comprehensive income/(expense)                                      | 469.9   | (26.6)  |\n",
            "| Total comprehensive income/(loss) for the financial year                  | 243.7   | (613.8) |\n",
            "\n",
            "Tables saved to: financial_tables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Balance Sheet Standardization Processor\n",
        "-------------------------------------\n",
        "Purpose: Extract and standardize Balance Sheet using allowed vocabulary terms\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional, List\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class BalanceSheetProcessor:\n",
        "    def __init__(self):\n",
        "        # Initialize OpenAI client\n",
        "        self.client = OpenAI(api_key=userdata.get('CLY'))\n",
        "\n",
        "        # Set up paths\n",
        "        self.tables_dir = Path(\"financial_tables\")\n",
        "        self.vocab_path = Path(\"/content/vocabulary.rtf\")\n",
        "\n",
        "        # Output paths\n",
        "        self.output_dir = Path(\"standardized_output\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Load vocabulary\n",
        "        self.vocabulary = self._load_vocabulary()\n",
        "        logger.info(f\"Loaded {len(self.vocabulary)} vocabulary terms\")\n",
        "\n",
        "    def _load_vocabulary(self) -> List[str]:\n",
        "        \"\"\"Load and clean vocabulary from RTF file\"\"\"\n",
        "        try:\n",
        "            with open(self.vocab_path, 'r') as f:\n",
        "                content = rtf_to_text(f.read())\n",
        "                terms = [\n",
        "                    term.strip(' \",\\\\')\n",
        "                    for term in content.split(',')\n",
        "                    if term.strip()\n",
        "                ]\n",
        "                # Filter and sort terms\n",
        "                return sorted([t for t in terms if t and not t.startswith('{')])\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Vocabulary loading failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def process_balance_sheet(self):\n",
        "        \"\"\"Main processing pipeline\"\"\"\n",
        "        try:\n",
        "            # Load source tables\n",
        "            tables = self._load_source_tables()\n",
        "            logger.info(f\"Loaded {len(tables)} tables\")\n",
        "\n",
        "            # Identify and extract Balance Sheet\n",
        "            balance_sheet = self._get_balance_sheet(tables)\n",
        "            if balance_sheet is None:\n",
        "                raise ValueError(\"Balance Sheet not found in input\")\n",
        "\n",
        "            # Standardize using vocabulary\n",
        "            standardized = self._standardize_terms(balance_sheet)\n",
        "\n",
        "            # Generate and save outputs\n",
        "            self._save_outputs(standardized)\n",
        "\n",
        "            return standardized\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Processing failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _load_source_tables(self) -> Dict[str, pd.DataFrame]:\n",
        "        \"\"\"Load tables from markdown file\"\"\"\n",
        "        try:\n",
        "            with open(self.tables_dir / \"financial_tables.md\", 'r') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Parse tables\n",
        "            tables = {}\n",
        "            current_table = None\n",
        "            current_lines = []\n",
        "\n",
        "            for line in content.split('\\n'):\n",
        "                if line.startswith('## '):\n",
        "                    if current_table and current_lines:\n",
        "                        tables[current_table] = self._parse_table(current_lines)\n",
        "                    current_table = line.replace('## ', '').strip()\n",
        "                    current_lines = []\n",
        "                elif line.strip():\n",
        "                    current_lines.append(line)\n",
        "\n",
        "            if current_table and current_lines:\n",
        "                tables[current_table] = self._parse_table(current_lines)\n",
        "\n",
        "            return tables\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Table loading failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_table(self, lines: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Parse markdown table into DataFrame\"\"\"\n",
        "        try:\n",
        "            # Get table content\n",
        "            table_lines = [\n",
        "                line.strip('|').strip()\n",
        "                for line in lines\n",
        "                if '|' in line and '-|-' not in line\n",
        "            ]\n",
        "\n",
        "            if not table_lines:\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            # Parse headers and data\n",
        "            headers = [col.strip() for col in table_lines[0].split('|')]\n",
        "            data = []\n",
        "\n",
        "            for line in table_lines[1:]:\n",
        "                cells = [cell.strip() for cell in line.split('|')]\n",
        "                if len(cells) == len(headers):\n",
        "                    data.append(cells)\n",
        "\n",
        "            return pd.DataFrame(data, columns=headers)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Table parsing failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _get_balance_sheet(self, tables: Dict[str, pd.DataFrame]) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Extract Balance Sheet table\"\"\"\n",
        "        for name, df in tables.items():\n",
        "            if any(term.lower() in name.lower()\n",
        "                  for term in ['balance sheet', 'financial position', 'statement of position']):\n",
        "                logger.info(f\"Found Balance Sheet: {name}\")\n",
        "                return df\n",
        "        return None\n",
        "\n",
        "    def _standardize_terms(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Standardize Balance Sheet terms using vocabulary\"\"\"\n",
        "        try:\n",
        "            # Extract line items\n",
        "            items = df.iloc[:, 0].tolist()\n",
        "\n",
        "            # Create mapping prompt\n",
        "            prompt = f\"\"\"\n",
        "            Task: Map these Balance Sheet line items to the standard vocabulary terms.\n",
        "\n",
        "            Original Balance Sheet items:\n",
        "            {json.dumps(items, indent=2)}\n",
        "\n",
        "            Allowed vocabulary terms:\n",
        "            {json.dumps(self.vocabulary, indent=2)}\n",
        "\n",
        "            Requirements:\n",
        "            1. Use ONLY terms from the allowed vocabulary list\n",
        "            2. Preserve the Balance Sheet structure:\n",
        "               - Assets (Current and Non-current)\n",
        "               - Liabilities (Current and Non-current)\n",
        "               - Equity\n",
        "            3. Map each term to its closest accounting equivalent\n",
        "            4. Use section headers (e.g., CURRENT ASSETS, NON CURRENT ASSETS) correctly\n",
        "            5. Maintain totals and subtotals using correct vocabulary terms\n",
        "\n",
        "            Return a JSON mapping where:\n",
        "            - Keys are the original terms\n",
        "            - Values are the matched allowed terms\n",
        "            Consider accounting standards and common financial terminology.\n",
        "            \"\"\"\n",
        "\n",
        "            # Get mappings from GPT-4\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a financial statement expert specializing in accounting terminology standardization.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Apply mappings\n",
        "            mapping = json.loads(response.choices[0].message.content)\n",
        "            standardized_df = df.copy()\n",
        "            standardized_df.iloc[:, 0] = standardized_df.iloc[:, 0].map(lambda x: mapping.get(x, x))\n",
        "\n",
        "            return standardized_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Term standardization failed: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _save_outputs(self, df: pd.DataFrame):\n",
        "        \"\"\"Save standardized Balance Sheet\"\"\"\n",
        "        try:\n",
        "            # Prepare markdown content\n",
        "            content = [\n",
        "                \"# Balance Sheet\\n\",\n",
        "                df.to_markdown(index=False),\n",
        "\n",
        "            ]\n",
        "\n",
        "            # Save markdown\n",
        "            output_path = self.output_dir / \"standardized_balance_sheet.md\"\n",
        "            with open(output_path, 'w') as f:\n",
        "                f.write('\\n'.join(content))\n",
        "\n",
        "            # Save CSV\n",
        "            df.to_csv(self.output_dir / \"standardized_balance_sheet.csv\", index=False)\n",
        "\n",
        "            # Display results\n",
        "            print(\"\\n✅ BALANCE SHEET STANDARDIZATION COMPLETE\")\n",
        "            print(\"\\n Balance Sheet:\")\n",
        "            print(df.to_markdown(index=False))\n",
        "            print(f\"\\nOutputs saved to: {self.output_dir}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Output generation failed: {e}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        processor = BalanceSheetProcessor()\n",
        "        processor.process_balance_sheet()\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ PROCESSING FAILED: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cf_daRigqq6",
        "outputId": "a250bd15-2a7b-48a5-8cc4-abc4726dca49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ BALANCE SHEET STANDARDIZATION COMPLETE\n",
            "\n",
            " Balance Sheet:\n",
            "| Line Item                                                 | 2020        | 2019        |\n",
            "|:----------------------------------------------------------|:------------|:------------|\n",
            "| :-------------------------------------------------------- | :---------- | :---------- |\n",
            "| NON CURRENT ASSETS                                        |             |             |\n",
            "| Other Intangible Assets                                   | 2,368.4     | 2,794.1     |\n",
            "| Land & Buildings                                          | 3,965.3     | 3,040.7     |\n",
            "| Non Current Related Party Assets                          | 25.1        | 25.1        |\n",
            "| Provisions and Deferred Taxes                             | 1,124.2     | 1,014.3     |\n",
            "| Other Non-Current Liabilities                             | 489.2       | 81.4        |\n",
            "| NON CURRENT ASSETS                                        | 7,972.2     | 6,955.6     |\n",
            "| CURRENT ASSETS                                            |             |             |\n",
            "| Inventory (Stock)                                         | 116.4       | 160.9       |\n",
            "| Accts Rec-Trade (Trade Debtors)                           | 3,582.2     | 3,400.8     |\n",
            "| Cash                                                      | 243         | 32.5        |\n",
            "| CURRENT ASSETS                                            | 3,722.9     | 3,594.2     |\n",
            "| Accts Payable - Trade (Trade Creditors)                   | (4,605.2)   | (4,215.1)   |\n",
            "| CURRENT LIABILITIES                                       | (882.3)     | (620.9)     |\n",
            "| TOTAL ASSETS                                              | 7,089.9     | 6,334.7     |\n",
            "| Long Term Debt                                            | (743.3)     | (21.6)      |\n",
            "| Provisions and Deferred Taxes                             | (217.1)     | (286.0)     |\n",
            "| Other Non-Current Liabilities                             | (19.2)      | (178.7)     |\n",
            "| TOTAL ASSETS                                              | 6,110.3     | 5,848.4     |\n",
            "| EQUITY                                                    |             |             |\n",
            "| Share Capital / Paid In Capital                           | -           | -           |\n",
            "| Other Equity                                              | 9,168.2     | 9,168.2     |\n",
            "| Retained Earnings                                         | (3,057.9)   | (3,319.8)   |\n",
            "| TOTAL EQUITY & LIABILITIES                                | 6,110.3     | 5,848.4     |\n",
            "|                                                           |             |             |\n",
            "\n",
            "Outputs saved to: standardized_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Function to display markdown content in Colab\n",
        "def display_markdown_from_file(file_path: str):\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            content = f.read()\n",
        "        display(Markdown(content))\n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying markdown: {e}\")\n",
        "\n",
        "# Display the output markdown\n",
        "display_markdown_from_file('/content/standardized_output/standardized_balance_sheet.md')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "o9c2c6iEmFtG",
        "outputId": "14f9f318-6e38-40c2-a94a-0cdb467bf158"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Balance Sheet\n\n| Line Item                                                 | 2020        | 2019        |\n|:----------------------------------------------------------|:------------|:------------|\n| :-------------------------------------------------------- | :---------- | :---------- |\n| NON CURRENT ASSETS                                        |             |             |\n| Other Intangible Assets                                   | 2,368.4     | 2,794.1     |\n| Land & Buildings                                          | 3,965.3     | 3,040.7     |\n| Non Current Related Party Assets                          | 25.1        | 25.1        |\n| Provisions and Deferred Taxes                             | 1,124.2     | 1,014.3     |\n| Other Non-Current Liabilities                             | 489.2       | 81.4        |\n| NON CURRENT ASSETS                                        | 7,972.2     | 6,955.6     |\n| CURRENT ASSETS                                            |             |             |\n| Inventory (Stock)                                         | 116.4       | 160.9       |\n| Accts Rec-Trade (Trade Debtors)                           | 3,582.2     | 3,400.8     |\n| Cash                                                      | 243         | 32.5        |\n| CURRENT ASSETS                                            | 3,722.9     | 3,594.2     |\n| Accts Payable - Trade (Trade Creditors)                   | (4,605.2)   | (4,215.1)   |\n| CURRENT LIABILITIES                                       | (882.3)     | (620.9)     |\n| TOTAL ASSETS                                              | 7,089.9     | 6,334.7     |\n| Long Term Debt                                            | (743.3)     | (21.6)      |\n| Provisions and Deferred Taxes                             | (217.1)     | (286.0)     |\n| Other Non-Current Liabilities                             | (19.2)      | (178.7)     |\n| TOTAL ASSETS                                              | 6,110.3     | 5,848.4     |\n| EQUITY                                                    |             |             |\n| Share Capital / Paid In Capital                           | -           | -           |\n| Other Equity                                              | 9,168.2     | 9,168.2     |\n| Retained Earnings                                         | (3,057.9)   | (3,319.8)   |\n| TOTAL EQUITY & LIABILITIES                                | 6,110.3     | 5,848.4     |\n|                                                           |             |             |"
          },
          "metadata": {}
        }
      ]
    }
  ]
}